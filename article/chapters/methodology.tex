\chapter{Methodology}
\label{chap:methodology}

This chapter describes the research methodology employed to
    investigate how AI Agent Protocols can enable semantic interoperability between
    heterogeneous Digital Twin systems.
The research follows a Design Science Research (DSR) approach, focusing on
    the design, development, and evaluation of a novel Digital Ecosystem architecture that leverages
    agent-mediated communication to solve cross-domain coordination challenges.

\section{Research Design}
\label{sec:research-design}

This research adopts the Design Science Research methodology proposed by
    Peffers et al.~\cite{peffers2007}, which provides a
    systematic framework for developing and evaluating Information Technology (IT) artifacts that
    address identified organizational problems.
DSR is particularly appropriate for this work because it
    emphasizes the creation and evaluation of
    purposeful artifacts---in this case,
    a Digital Ecosystem architecture and its proof-of-concept implementation.

The DSR process consists of six iterative activities:

\begin{enumerate}
    \item \textbf{Problem Identification and Motivation:}
    Addressed in Chapters~\ref{chap:introduction} and~\ref{chap:related-work},
    identifying the semantic interoperability challenge in heterogeneous DT systems.
    
    \item \textbf{Objectives of a Solution:}
    Defined in Section~\ref{sec:objectives},
    focusing on agent-mediated interoperability while preserving system autonomy.
    
    \item \textbf{Design and Development:}
    Described in Sections~\ref{sec:architecture-design} and~\ref{sec:implementation-methodology},
    covering the Digital Ecosystem architecture and agent protocol integration.
    
    \item \textbf{Demonstration:}
    Presented in Section~\ref{sec:use-case},
    using a realistic cross-domain scenario involving Smart City and Energy Grid DTs.
    
    \item \textbf{Evaluation:}
    Detailed in Section~\ref{sec:evaluation},
    with metrics assessing
    semantic mapping capabilities,
    integration effort, and
    functional success.
    
    \item \textbf{Communication:}
    Fulfilled through this thesis.
\end{enumerate}

\section{System Architecture Design}
\label{sec:architecture-design}

The proposed Digital Ecosystem architecture
    depicted in Figure~\ref{fig:architecture} adopts a
    layered design inspired by
    DestinE virtual cloud layer concept~\cite{Nativi_2021}, 
    adapting its separation of concerns principles to agent-mediated Digital Twin interoperability.
Moreover, this OSI-inspired layering~\cite{day1983} provides clear separation between
    user interaction (Application),
    protocol translation (Presentation),
    conversation management (Session) and
    resource access (Domain, Platform, Data).

\begin{figure}[htbp]
    \centering
    \includegraphics[height=0.85\textheight,keepaspectratio]{figures/architecture.pdf}
    \caption{
        Agent-mediated Digital Twin interoperability architecture.
        The layered design integrates group chat patterns with MCP-based resource discovery
            to enable dynamic semantic negotiation between heterogeneous DT platforms.
    }
    \label{fig:architecture}
\end{figure}

\subsection{Application Layer}
\label{subsec:application-layer}

The application layer defines the end user that interacts with the Digital Ecosystem,
    which can be a human operator or an automated service.
A complex goal that requires assistance from multiple DT platforms is
    elaborated by the end user, then submitted to the system via agent.
Such goals may involve cross-domain queries, data aggregation, or coordinated actions
    that exceed the capabilities of any single DT platform.
Moreover, the application layer abstracts away platform-specific details,
    allowing users to focus on high-level objectives without needing to understand
    the underlying DT implementations.

\subsection{Presentation Layer}
\label{subsec:presentation-layer}

The presentation layer translates user intents into structured requests
    that can be processed by the Digital Ecosystem.
Specifically, the layer shall provide an application, service or AI agent that
    acts on behalf of the user
    to communicate with the Digital Ecosystem's agent through the A2A protocol.
This segregation allows the user application to remain agnostic of
    the underlying agent communication mechanisms,
    granting modularity and easier maintenance.
Furthermore to this point, the presentation layer may be implemented either as
    part of the Digital Ecosystem,
    integrated into the user application itself or
    provided as a third-party service,
    depending on the specific use case and system requirements.

\subsection{Session Layer}
\label{subsec:session-layer}

The session layer orchestrates multi-agent conversations that coordinate
    cross-domain interactions between heterogeneous DT platforms and user agents.
Unlike traditional orchestration approaches that rely on predetermined workflows,
    this layer enables dynamic task solving where the exact interaction sequence
    emerges from ongoing agent conversations rather than following pre-defined patterns.
This design is particularly suited for complex scenarios involving semantic interoperability,
    where the optimal coordination strategy cannot be determined a priori due to
    heterogeneous ontologies and unpredictable cross-domain dependencies.

The \textbf{Group Chat Manager} component realizes these principles through
    AutoGen's group chat pattern~\cite{wu2024autogen}, adapted for Digital Twin interoperability.
In this pattern, participating agents share the same conversation context and
    interact dynamically without strict communication order,
    enabling collaborative problem-solving that adapts to the specific characteristics
    of each cross-domain request.

The Group Chat Manager operates through three iterative steps.
First, it \textbf{dynamically selects a speaker} from available domain agents
    based on conversation context and role alignment.
This selection uses role-play prompts that consider both the current state of
    the cross-domain request and each agent's domain expertise,
    ensuring that the most appropriate agent contributes at each conversation turn.
Second, it \textbf{collects responses} from the selected agent,
    which may include semantic mappings, data queries, or requests for clarification
    from other domain agents.
Third, it \textbf{broadcasts messages} to all participating agents,
    maintaining shared context and enabling any agent to respond when their expertise is needed.

Resources are exclusively accessed through domain layer agents,
    which encapsulate platform-specific logic and knowledge.
The Group Chat Manager never directly interacts with DT platforms or their data sources;
    instead, it facilitates A2A protocol conversations among domain agents,
    which themselves use the Model Context Protocol (MCP) to
    query their respective platforms.
This protocol layering ensures clean separation between
    inter-agent coordination (A2A, session layer) and
    platform resource access (MCP, domain/platform layers).

Such design preserves platform autonomy,
    as domain agents mediate all interactions without external entities
    accessing their platforms' internals.
Digital Environment capabilities are exposed only through agent interfaces,
    enabling semantic mappings to be negotiated dynamically based on each request's context
    rather than requiring pre-coordinated schemas.
Aligned with DestinE's principles~\cite{Nativi_2021}, the session layer ensures that
    each DT platform retains full autonomy over its internal operations while
    participating in collaborative workflows mediated by agents.

Although not in this research scope, the session layer may enforce governance policies.
This includes ensuring that all interactions comply with
    security, privacy, and operational constraints
    defined by the Digital Environment administrators.
Policy enforcement occurs at the Group Chat Manager boundary, enabling centralized control
    while keeping domain agents focused on their platform-specific responsibilities.

\subsection{Domain Layer}
\label{subsec:domain-layer}

The domain layer encapsulates platform-specific agents that
    mediate interactions between the session layer and individual Digital Twin platforms.
Each \textbf{Digital Twin Agent} act as a domain specialist for a specific DT platform,
    understanding its native knowledge representation, ontology, and query capabilities.
These agents serve as semantic translators,
    exposing their platform's resources through the Model Context Protocol (MCP)
    while negotiating cross-domain mappings through the Agent-to-Agent (A2A) protocol.
To achieve semantic interoperability, besides being \textbf{domain-aware},
    each Digital Twin Agent must be capable to reason about
    semantic equivalences with other domains.
By isolating platform heterogeneity within dedicated agents,
    the domain layer enables seamless integration of diverse DT systems
    without requiring direct interoperability between platforms themselves.

\subsection{Platform Layer}
\label{subsec:platform-layer}

The platform layer consists of individual Digital Twin systems
    that manage domain-specific digital representations of physical assets.
Each DT platform exposes its capabilities through a Model Context Protocol (MCP) server,
    enabling agents to discover available resources and their schemas dynamically.
This layer abstracts away the underlying implementation details of each DT platform,
    allowing agents to interact with them through a standardized interface.

\subsection{Data Layer}
\label{subsec:data-layer}

The data layer encompasses the physical and digital resources
    that underpin each Digital Twin platform.
This includes physical sensors, simulation models, historical datasets,
    and any other data sources that contribute to the DT's knowledge base.
Each DT platform is responsible for managing its data layer autonomously,
    ensuring data integrity, security, and availability according to its own policies.
Agents access data indirectly through their associated DT platforms,
    leveraging the platforms' native capabilities for data retrieval and processing.

\section{Implementation Methodology}
\label{sec:implementation-methodology}

The proof-of-concept implementation realizes the proposed Digital Ecosystem architecture through
    a concrete deployment integrating heterogeneous Digital Twin platforms mediated by AI agents.
Figure~\ref{fig:poc-architecture} illustrates the implementation architecture,
    showing the integration of KTWIN and Eclipse Ditto platforms through agent-based coordination.

\begin{figure}[htbp]
    \centering
    \includegraphics[width=\textwidth]{figures/proof-of-concept.pdf}
    \caption{Proof-of-concept implementation architecture}
    \label{fig:poc-architecture}
\end{figure}

\subsection{User Application Component}
\label{subsec:user-application-component}

The User Application Component provides the end-user interface through which
    requests are submitted to the Digital Ecosystem.
To ensure research reproducibility while avoiding proprietary constraints,
    we use \textbf{Open WebUI}~\cite{baek2025},
    an open-source self-hosted AI interface that enables flexible agent protocol integration.

Open WebUI serves as both the user interface and agent client,
    translating natural language user requests into structured agent communications.
The platform's extensibility allows implementation of custom Agent-to-Agent (A2A) protocol clients
    without vendor lock-in to proprietary chat interfaces or cloud services.

\subsection{Digital Ecosystem Orchestration}
\label{subsec:digital-ecosystem-orchestration}

The Digital Ecosystem's agent communication is realized through
    \textbf{AutoGen}~\cite{wu2024autogen},
    an open-source AI agent framework focused on multi-agent conversation.
Participating agents can
    share conversation context and
    interact without predetermined communication sequences.
This provides the foundation for implementing the
    Group Chat Manager component described in Section~\ref{subsec:session-layer}.

AutoGen's speaker selection mechanism can be configured with custom logic that
    prioritizes agents based on conversation context analysis,
    ensuring semantic negotiation progresses efficiently toward cross-domain resolution.
The LLM backend flexibility enables evaluation across both
    cloud-based models (E.g.: Claude Sonnet 3.5 via Anthropic API) and
    locally-hosted alternatives (E.g.: Llama 3 via Ollama).
This facilitates prototyping under realistic constraints while
    supporting performance comparison and cost-sensitive deployment scenarios.

\subsection{Digital Twin Platform Components}
\label{subsec:digital-twin-platform-components}

Two open-source DT platforms were selected to demonstrate heterogeneous system integration
    while maintaining realistic semantic complexity.
The selection criteria prioritized platforms with
    sufficient heterogeneity to require semantic mediation, and
    extensibility to support MCP server integration.

\textbf{KTWIN}~\cite{Wermann_Wickboldt_2025} implements the Smart City DT platform.
KTWIN is a Kubernetes-based serverless framework designed to 
    simplify DT adoption through cloud-native deployment patterns.
It natively supports the Digital Twins Definition Language (DTDL) and has been
    validated for smart city applications using the
    \texttt{opendigitaltwins-smartcities} ontology.
This ontology provides comprehensive models for
    urban infrastructure entities including
    parking facilities,
    EV charging stations,
    traffic sensors, and
    building management systems.

Key technical characteristics include:

\begin{itemize}
    \item \textbf{Serverless Event-Driven Architecture:}
    Function-as-a-Service (FaaS) deployment enables
        automatic scaling and
        reduced operational overhead, while
        the centralized event broker (RabbitMQ) supports
        real-time state updates through
        multiple protocols (MQTT, HTTP, AMQP).

    \item \textbf{Kubernetes-Native Infrastructure:}
    Custom Resource Definitions (CRDs) and operators automate
        infrastructure provisioning based on
        DTDL ontology definitions,
        enabling multi-cloud and edge deployments without vendor lock-in.
    
    \item \textbf{Ontology-Driven Automation:}
    Native DTDL support eliminates schema translation overhead,
        allowing direct implementation of the \texttt{smartcities} ontology concepts.
\end{itemize}

\textbf{Eclipse Ditto} implements the Energy Grid DT platform.
Ditto is a mature open-source IoT platform providing
    DT capabilities through its ``Thing'' abstraction,
    widely adopted in industrial IoT deployments.
For this research, Ditto manages twins conforming to the
    \texttt{opendigitaltwins-energygrid} ontology, which adapts the
    Common Information Model (CIM) standard---the energy industry's reference ontology---to DTDL.
Since Ditto's native knowledge representation uses the Thing model,
    schema translation will be necessary for this research.

Key technical characteristics include:

\begin{itemize}
    \item \textbf{Thing-Based Knowledge Representation:}
    Distinct from KTWIN's DTDL approach,
        necessitating genuine semantic mapping rather than trivial schema alignment
    
    \item \textbf{Rich REST and WebSocket APIs:}
    Well-documented interfaces simplify MCP server implementation for resource access
    
    \item \textbf{RabbitMQ Integration:}
    Similar messaging infrastructure to KTWIN reduces deployment complexity
        while maintaining semantic heterogeneity at the ontology level
    
    \item \textbf{Production-Grade Maturity:}
    Extensive documentation, active community, and industrial adoption
        ensure realistic platform behavior for evaluation
\end{itemize}

The deliberate selection of platforms with similar
    messaging infrastructure (RabbitMQ) but
    different knowledge representations (native DTDL vs. Thing model)
    creates the realistic heterogeneity necessary to
    validate agent-mediated semantic interoperability while
    maintaining implementation feasibility within research constraints.
Neither platform provides native MCP server capabilities.
Implementing MCP servers for both KTWIN and Eclipse Ditto
    constitutes part of this research scope.

\subsection{Agent-Platform Integration}
\label{subsec:agent-interaction-impl}

While Section~\ref{subsec:session-layer} described
    agent-to-agent coordination through the A2A protocol,
    this subsection focuses on the complementary agent-to-platform interaction pattern
    realized through the Model Context Protocol (MCP).
MCP enables dynamic resource discovery and query execution without requiring agents to
    maintain platform-specific client code or
    hardcoded schema knowledge.

Each DT platform exposes an MCP server.
The server publishes three types of information:
    resource catalogs (available entity types and instances),
    schema metadata (properties, relationships, semantic annotations), and
    query capabilities (supported operations like filtering, spatial queries, aggregation).
For KTWIN, the MCP server wraps Kubernetes CRDs and RabbitMQ event streams,
    exposing \texttt{smart-city} ontology entities.
For Ditto, the MCP server interfaces with REST and WebSocket APIs,
    querying \texttt{energy-grid} ontology entities.

Each domain agent embeds an MCP client
    that connects to its associated platform's MCP server.
The client provides the agent's LLM with tool definitions for
    discovering resources,
    retrieving schemas, and
    executing queries with filtering and projection.
This architecture enables agents to dynamically discover platform capabilities through MCP,
    negotiate semantic mappings through A2A conversations, and
    execute coordinated queries to solve cross-domain problems---all
    without requiring modifications to the underlying DT platforms beyond MCP server deployment.

\section{Cross-Domain Use Case Definition}
\label{sec:use-case}

To validate the agent-mediated interoperability approach, a realistic cross-domain scenario has been designed that requires
    cooperation between Smart City and Energy Grid DT systems.

\subsection{Scenario Description: Dynamic EV Charging Coordination}
\label{subsec:scenario-description}

The use case addresses a practical urban energy management challenge:
    coordinating electric vehicle (EV) charging to prevent distribution grid overloads while maximizing charging service availability.

\textbf{Problem Context:}
During peak demand periods (e.g., 5-7 PM), large numbers of EVs require charging in urban areas.
Simultaneously, building loads and other consumers already stress the distribution network.
Uncoordinated EV charging can overload transformers, causing equipment damage, service interruptions, or cascading failures.

\textbf{Cross-Domain Requirement:}
Neither the Smart City DT nor the Energy Grid DT can solve this problem independently:
\begin{itemize}
    \item The Smart City DT knows EV locations, parking availability, and charging station infrastructure, but lacks knowledge of grid capacity constraints
    \item The Energy Grid DT monitors transformer loads and distribution network capacity, but has no visibility into EV movement or charging demand
\end{itemize}

\textbf{Scenario Execution:}
\begin{enumerate}
    \item 50 EVs enter downtown area between 5-7 PM, each requiring charging within 2 hours
    \item Multiple charging stations are available with varying capacities (7 kW, 22 kW, 50 kW fast chargers)
    \item Distribution transformers serving different downtown zones have different available capacities
    \item The system must assign EVs to charging stations that satisfy both:
        \begin{itemize}
            \item Parking availability and driver preferences (Smart City constraint)
            \item Transformer capacity limits (Energy Grid constraint)
        \end{itemize}
\end{enumerate}

\textbf{Success Criteria:}
\begin{itemize}
    \item All 50 EVs successfully charged within time window
    \item No transformer exceeds 95\% rated capacity
    \item System adapts if charging station status changes
    \item Cross-domain coordination achieved without manual integration code
\end{itemize}

\subsection{Semantic Gap Characterization}
\label{subsec:semantic-gaps}

The scenario requires bridging multiple semantic gaps between the
    \texttt{smart-city} ontology (KTWIN) and the
    \texttt{energy-grid} ontology (Ditto).
These gaps are representative of real-world DT integration challenges:
    different domains model the same physical infrastructure from different perspectives using
    domain-specific ontologies optimized for their use cases.

\begin{table}[ht]
    \centering
    \small
    \begin{tabular}{ | m{4cm} | m{4cm} | m{5cm} | }
        \hline

        \textbf{Smart City Concept} & \textbf{Energy Grid Concept} & \textbf{Semantic Challenge} \\
        \hline

            \texttt{EVChargingStation} 

            (physical location) &
            \texttt{UsagePoint}

            (logical metering point) &
            Different abstraction levels: physical infrastructure vs. logical measurement point \\
        \hline

            \texttt{capacity}, \texttt{availableCapacity}
            
            (vehicles that can charge) &
            \texttt{ratedPower}, \texttt{estimatedLoad}
            
            (power capacity and consumption) &
            Different measurement units and semantics: vehicle count vs. electrical power metrics \\
        \hline

            \texttt{amperage}
        
            (electrical properties) &
            \texttt{ratedCurrent}
            
            (service ratings) &
            Similar concepts with different property names and potentially different semantic intent \\
        \hline

            \texttt{status} enum
            
            (working, outOfService, etc.) &
            \texttt{connectionState}, \texttt{amiBillingReady} &
            Operational state represented differently: service availability vs. connection/billing status \\
        \hline
    \end{tabular}
    \caption{Semantic gaps requiring agent-mediated mapping}
    \label{tab:semantic-gaps}
\end{table}

\section{Evaluation Methodology}
\label{sec:evaluation}

The evaluation assesses whether agent-mediated interoperability achieves the claimed benefits over
    traditional integration approaches across three dimensions:
    semantic capability, integration effort, and functional performance. 
Table~\ref{tab:evaluation-metrics} covers these dimensions through several quantitative metrics.
These metrics collectively provide evidence for evaluating 
    DT interoperability improved by AI agent protocols while preserving system autonomy.

\begin{table}[H]
    \centering
    \small
    \begin{tabular}{|p{5cm}|p{5cm}|p{3cm}|}
        \hline
        
            \textbf{Metric} & \textbf{Measurement Method} & \textbf{Target Value} \\
        \hline
        
            \multicolumn{3}{|c|}{\textit{Semantic Interoperability}} \\
        \hline
        
            Semantic mapping coverage & \% of required concept mappings successfully established & >90\% \\
        \hline
        
            Zero-configuration integration & Number of manual semantic mappings required & 0 (fully automated) \\
        \hline
        
            Schema evolution tolerance & System adapts when new property added to ChargingStation? & Yes (no code changes) \\
        \hline
        
            Mapping negotiation time & Time for agents to establish initial mappings & <30 seconds \\
        \hline
        
            \multicolumn{3}{|c|}{\textit{Integration Effort}} \\
        \hline
        
            Implementation complexity & Lines of integration code (excluding agent framework) & <500 LOC \\
        \hline
        
            Configuration burden & Number of configuration files/mappings & <5 config files \\
        \hline
        
            Time to extend & Estimated hours to add 3rd DT platform (Weather) & <8 hours \\
        \hline
        
            \multicolumn{3}{|c|}{\textit{Functional Effectiveness}} \\
        \hline
        
            Cross-domain query success & \% of queries returning correct combined results & >95\% \\
        \hline
        
            Charging task completion & \% of 50 EVs successfully charged & 100\% \\
        \hline
        
            Grid constraint satisfaction & \% of time transformers remain below 95\% capacity & 100\% \\
        \hline
        
            Response time & End-to-end latency for charging assignment request & <5 seconds \\
        \hline
    \end{tabular}
    \caption{Evaluation metrics and targets}
    \label{tab:evaluation-metrics}
\end{table}

\subsection{Baseline Comparison}
\label{subsec:baseline-comparison}

To demonstrate the value of agent-mediated interoperability, two baseline approaches will be implemented for comparison:

\textbf{Baseline 1: Manual REST API Integration}

A traditional point-to-point integration approach:
\begin{itemize}
    \item Custom Python code queries KTWIN REST API for charging station data
    \item Separate custom code queries Ditto REST API for transformer data
    \item Hardcoded mapping logic translates between ontologies
    \item Static configuration file defines ChargingStation $\rightarrow$ UsagePoint relationships
\end{itemize}

\textit{Measurement focus:} Lines of code, configuration complexity, time to implement, brittleness to schema changes.

\textbf{Baseline 2: Shared Ontology Approach}

A unified semantic layer approach:
\begin{itemize}
    \item Design common ``EnergyInfrastructure'' ontology spanning both domains
    \item Implement exporters forcing KTWIN and Ditto to translate to shared schema
    \item Centralized query engine operates on unified model
\end{itemize}

\textit{Measurement focus:} Ontology development effort, deployment complexity, operational overhead, evolution challenges.

\textbf{Comparative Analysis:}

\begin{table}[ht]
    \centering
    \small
    \begin{tabular}{|l|c|c|c|}
        \hline
        
            \textbf{Evaluation Aspect} & \textbf{Manual API} & \textbf{Shared Ontology} & \textbf{Agent-Mediated} \\
        \hline
        
            Initial implementation time & Baseline & +50\% & +20\% \\
        
            Lines of integration code & Baseline & +30\% & -70\% \\
        
            Schema change impact & High & Medium & Low \\
        
            3rd system integration time & Baseline & +40\% & -60\% \\
        
            Runtime overhead & Low & Medium & Medium \\
        
            Semantic flexibility & None & Low & High \\
        \hline
    \end{tabular}
    \caption{Expected comparative results (to be validated)}
    \label{tab:baseline-comparison}
\end{table}

\subsection{Validation Approach}
\label{subsec:validation-approach}

The proof-of-concept will be validated through:

\textbf{Functional Validation:}
\begin{enumerate}
    \item \textbf{Nominal Scenario:} Execute base case with 50 EVs, verify all constraints satisfied
    \item \textbf{Stress Test:} Increase to 100 EVs, verify graceful degradation (some EVs delayed, no overloads)
    \item \textbf{Schema Evolution:} Add new property to ChargingStation DTDL, verify agents adapt without code changes
    \item \textbf{Failure Handling:} Simulate charging station outage, verify agents reroute EVs
\end{enumerate}

\textbf{Semantic Mapping Validation:}
\begin{itemize}
    \item Manual inspection of agent-negotiated mappings for correctness
    \item Sample validation: Execute 20 cross-domain queries, verify accuracy against ground truth
    \item Ontology expert review of mapping quality
\end{itemize}

\textbf{Performance Validation:}
\begin{itemize}
    \item Measure end-to-end latency for 100 requests
    \item Monitor resource utilization (CPU, memory, network) during peak load
    \item Compare against baseline approaches for equivalent workload
\end{itemize}

\textbf{Qualitative Assessment:}
\begin{itemize}
    \item Developer experience: subjective assessment of implementation effort
    \item Maintainability: estimated effort to update mappings vs. baseline
    \item Extensibility: feasibility analysis for adding Weather DT
\end{itemize}
