 @article{Wermann_Wickboldt_2025,
  title        = {KTWIN: A Serverless Kubernetes-based Digital Twin Platform},
  volume       = {259},
  issn         = {1389-1286},
  url          = {https://www.sciencedirect.com/science/article/pii/S1389128625000635},
  doi          = {https://doi.org/10.1016/j.comnet.2025.111095},
  abstractnote = {Digital Twins (DTs) systems are virtual representations of physical assets allowing organizations to gain insights and improve existing processes. In practice, DTs require proper modeling, coherent development and seamless deployment along cloud and edge landscapes relying on established patterns to reduce operational costs. In this work, we propose KTWIN a Kubernetes-based Serverless Platform for Digital Twins. KTWIN was developed using the state-of-the-art open-source Cloud Native tools, allowing DT operators to easily define models through open standards and configure details of the underlying services and infrastructure. The experiments carried out with the developed prototype show that KTWIN can provide a higher level of abstraction to model and deploy a Digital Twin use case without compromising the solution scalability. The tests performed also show cost savings ranging between 60% and 80% compared to overprovisioned scenarios.},
  journal      = {Computer Networks},
  author       = {Wermann, Alexandre Gustavo and Wickboldt, Juliano Araujo},
  year         = {2025},
  pages        = {111095}
}

 @article{Fuller_Fan_Day_Barlow_2020,
  title        = {Digital Twin: Enabling Technologies, Challenges and Open Research},
  volume       = {8},
  issn         = {2169-3536},
  url          = {https://ieeexplore.ieee.org/abstract/document/9103025},
  doi          = {10.1109/ACCESS.2020.2998358},
  abstractnote = {Digital Twin technology is an emerging concept that has become the centre of attention for industry and, in more recent years, academia. The advancements in industry 4.0 concepts have facilitated its growth, particularly in the manufacturing industry. The Digital Twin is defined extensively but is best described as the effortless integration of data between a physical and virtual machine in either direction. The challenges, applications, and enabling technologies for Artificial Intelligence, Internet of Things (IoT) and Digital Twins are presented. A review of publications relating to Digital Twins is performed, producing a categorical review of recent papers. The review has categorised them by research areas: manufacturing, healthcare and smart cities, discussing a range of papers that reflect these areas and the current state of research. The paper provides an assessment of the enabling technologies, challenges and open research for Digital Twins.},
  journal      = {IEEE Access},
  author       = {Fuller, Aidan and Fan, Zhong and Day, Charles and Barlow, Chris},
  year         = {2020},
  pages        = {108952–108971}
}

 @article{Hu_Zhang_Deng_Liu_Tan_2021,
  title        = {Digital twin: a state-of-the-art review of its enabling technologies, applications and challenges},
  volume       = {2},
  issn         = {2633-6596},
  url          = {https://doi.org/10.1108/JIMSE-12-2020-010},
  doi          = {10.1108/JIMSE-12-2020-010},
  abstractnote = {Digital twin (DT) is an emerging technology that enables sophisticated interaction between physical objects and their virtual replicas. Although DT has recently gained significant attraction in both industry and academia, there is no systematic understanding of DT from its development history to its different concepts and applications in disparate disciplines. The majority of DT literature focuses on the conceptual development of DT frameworks for a specific implementation area. Hence, this paper provides a state-of-the-art review of DT history, different definitions and models, and six types of key enabling technologies. The review also provides a comprehensive survey of DT applications from two perspectives: (1) applications in four product-lifecycle phases, i.e. product design, manufacturing, operation and maintenance, and recycling and (2) applications in four categorized engineering fields, including aerospace engineering, tunneling and underground engineering, wind engineering and Internet of things (IoT) applications. DT frameworks, characteristic components, key technologies and specific applications are extracted for each DT category in this paper. A comprehensive survey of the DT references reveals the following findings: (1) The majority of existing DT models only involve one-way data transfer from physical entities to virtual models and (2) There is a lack of consideration of the environmental coupling, which results in the inaccurate representation of the virtual components in existing DT models. Thus, this paper highlights the role of environmental factor in DT enabling technologies and in categorized engineering applications. In addition, the review discusses the key challenges and provides future work for constructing DTs of complex engineering systems.},
  number       = {1},
  journal      = {Journal of Intelligent Manufacturing and Special Equipment},
  author       = {Hu, Weifei and Zhang, Tongzhou and Deng, Xiaoyu and Liu, Zhenyu and Tan, Jianrong},
  year         = {2021},
  month        = jul,
  pages        = {1–34}
}

 @article{Qi_Tao_Hu_Anwer_Liu_Wei_Wang_Nee_2021,
  series       = {Digital Twin towards Smart Manufacturing and Industry 4.0},
  title        = {Enabling technologies and tools for digital twin},
  volume       = {58},
  issn         = {0278-6125},
  url          = {https://www.sciencedirect.com/science/article/pii/S027861251930086X},
  doi          = {10.1016/j.jmsy.2019.10.001},
  abstractnote = {Digital twin is revolutionizing industry. Fired by sensor updates and history data, the sophisticated models can mirror almost every facet of a product, process or service. In the future, everything in the physical world would be replicated in the digital space through digital twin technology. As a cutting-edge technology, digital twin has received a lot of attention. However, digital twin is far from realizing their potential, which is a complex system and long-drawn process. Researchers must model all the different parts of the objects or systems. Varied types of data needed to be collected and merged. Many researchers and participators in engineering are not clear which technologies and tools should be used. 5-dimension digital twin model provides reference guidance for understanding and implementing digital twin. From the perspective of 5-dimension digital twin model, this paper tries to investigate and summarize the frequently-used enabling technologies and tools for digital twin to provide technologies and tools references for the applications of digital twin in the future.},
  journal      = {Journal of Manufacturing Systems},
  author       = {Qi, Qinglin and Tao, Fei and Hu, Tianliang and Anwer, Nabil and Liu, Ang and Wei, Yongli and Wang, Lihui and Nee, A. Y. C.},
  year         = {2021},
  month        = jan,
  pages        = {3–21},
  collection   = {Digital Twin towards Smart Manufacturing and Industry 4.0}
}

 @article{Alnaser_Maxi_Elmousalami_2024,
  title        = {AI-Powered Digital Twins and Internet of Things for Smart Cities and Sustainable Building Environment},
  volume       = {14},
  rights       = {http://creativecommons.org/licenses/by/3.0/},
  issn         = {2076-3417},
  url          = {https://www.mdpi.com/2076-3417/14/24/12056},
  doi          = {10.3390/app142412056},
  abstractnote = {This systematic literature review explores the intersection of AI-driven digital twins and IoT in creating a sustainable building environment. A comprehensive analysis of 125 papers focuses on four major themes. First, digital twins are examined in construction, facility management, and their role in fostering sustainability and smart cities. The integration of IoT and AI with digital twins and energy optimization for zero-energy buildings is discussed. Second, the application of AI and automation in manufacturing, particularly in Industry 4.0 and cyber-physical systems, is evaluated. Third, emerging technologies in urban development, including blockchain, cybersecurity, and EEG-driven systems for sustainable buildings, are highlighted. The study underscores the role of data-driven approaches in flood resilience and urban digital ecosystems. This review contributes to sustainability by identifying how digital technologies and AI can optimize energy use and enhance resilience in both urban and industrial contexts.},
  number       = {24},
  journal      = {Applied Sciences},
  publisher    = {Multidisciplinary Digital Publishing Institute},
  author       = {Alnaser, Aljawharah A. and Maxi, Mina and Elmousalami, Haytham},
  year         = {2024},
  month        = jan,
  pages        = {12056},
  language     = {en}
}

 @article{Sarp_Kuzlu_Jovanovic_Polat_Guler_2024,
  title        = {Digitalization of railway transportation through AI-powered services: digital twin trains},
  volume       = {16},
  issn         = {1866-8887},
  url          = {https://doi.org/10.1186/s12544-024-00679-5},
  doi          = {10.1186/s12544-024-00679-5},
  abstractnote = {Digitalization is a key concept that transformed the various industries through technologies like Internet of Things (IoT), Artificial Intelligence (AI), and Digital Twin (DT). Although innovations provided by the advancement of digitalization have paved the way for more efficient operations and products for transportation, the rail transportation sector struggles to keep up with the rest of the transportation industry, since trains are designed to last for decades, and the insufficient infrastructure investment leads to multiple railroad derailments across the globe. Therefore, the primary aim is to transform current railway systems into human-centric, adaptable, sustainable and future-proof networks, aligning with Industry 5.0 (I5.0) and Circular Economy (CE) model supported by the restorative and long-lasting design of the trains. This transformation necessitates leveraging digitalization and emerging technologies to address the needs of passengers, operators, and maintenance personnel. This article provides a comprehensive review focusing on the application of IoT, AI, CE principles, and digital twin trains to existing railway infrastructure and assets. The analysis delves into developing system architecture for proposed solutions and their impact on operation, maintenance, sustainability, and passenger comfort, supported by track record analysis. The integration of these technologies and concepts, particularly AI-powered services, is anticipated to yield immediate advancements in the digitalization of railway transportation, enhancing efficiency and safety measures.},
  number       = {1},
  journal      = {European Transport Research Review},
  author       = {Sarp, Salih and Kuzlu, Murat and Jovanovic, Vukica and Polat, Zekeriya and Guler, Ozgur},
  year         = {2024},
  month        = oct,
  pages        = {58},
  language     = {en}
}

 @article{Avanzato_Beritelli_Lombardo_Ricci_2024,
  title        = {Lung-DT: An AI-Powered Digital Twin Framework for Thoracic Health Monitoring and Diagnosis},
  volume       = {24},
  rights       = {http://creativecommons.org/licenses/by/3.0/},
  issn         = {1424-8220},
  url          = {https://www.mdpi.com/1424-8220/24/3/958},
  doi          = {10.3390/s24030958},
  abstractnote = {The integration of artificial intelligence (AI) with Digital Twins (DTs) has emerged as a promising approach to revolutionize healthcare, particularly in terms of diagnosis and management of thoracic disorders. This study proposes a comprehensive framework, named Lung-DT, which leverages IoT sensors and AI algorithms to establish the digital representation of a patient’s respiratory health. Using the YOLOv8 neural network, the Lung-DT system accurately classifies chest X-rays into five distinct categories of lung diseases, including “normal”, “covid”, “lung_opacity”, “pneumonia”, and “tuberculosis”. The performance of the system was evaluated employing a chest X-ray dataset available in the literature, demonstrating average accuracy of 96.8%, precision of 92%, recall of 97%, and F1-score of 94%. The proposed Lung-DT framework offers several advantages over conventional diagnostic methods. Firstly, it enables real-time monitoring of lung health through continuous data acquisition from IoT sensors, facilitating early diagnosis and intervention. Secondly, the AI-powered classification module provides automated and objective assessments of chest X-rays, reducing dependence on subjective human interpretation. Thirdly, the twin digital representation of the patient’s respiratory health allows for comprehensive analysis and correlation of multiple data streams, providing valuable insights as to personalized treatment plans. The integration of IoT sensors, AI algorithms, and DT technology within the Lung-DT system demonstrates a significant step towards improving thoracic healthcare. By enabling continuous monitoring, automated diagnosis, and comprehensive data analysis, the Lung-DT framework has enormous potential to enhance patient outcomes, reduce healthcare costs, and optimize resource allocation.},
  number       = {3},
  journal      = {Sensors},
  publisher    = {Multidisciplinary Digital Publishing Institute},
  author       = {Avanzato, Roberta and Beritelli, Francesco and Lombardo, Alfio and Ricci, Carmelo},
  year         = {2024},
  month        = jan,
  pages        = {958},
  language     = {en}
}

 @article{Muctadir_2024,
  title        = {Current trends in digital twin development, maintenance, and operation: an interview study},
  volume       = {23},
  issn         = {1619-1374},
  url          = {https://doi.org/10.1007/s10270-024-01167-z},
  doi          = {10.1007/s10270-024-01167-z},
  abstractnote = {Digital twins (DTs) are often defined as a pairing of a physical entity and a corresponding virtual entity (VE), mimicking certain aspects of the former depending on the use-case. In recent years, this concept has facilitated numerous use-cases ranging from design to validation and predictive maintenance of large and small high-tech systems. Various heterogeneous cross-domain models are essential for such systems, and model-driven engineering plays a pivotal role in the design, development, and maintenance of these models. We believe models and model-driven engineering play a similarly crucial role in the context of a VE of a DT. Due to the rapidly growing popularity of DTs and their use in diverse domains and use-cases, the methodologies, tools, and practices for designing, developing, and maintaining the corresponding VEs differ vastly. To better understand these differences and similarities, we performed a semi-structured interview research with 19 professionals from industry and academia who are closely associated with different lifecycle stages of digital twins. In this paper, we present our analysis and findings from this study, which is based on seven research questions. In general, we identified an overall lack of uniformity in terms of the understanding of digital twins and used tools, techniques, and methodologies for the development and maintenance of the corresponding VEs. Furthermore, considering that digital twins are software intensive systems, we recognize a significant growth potential for adopting more software engineering practices, processes, and expertise in various stages of a digital twin’s lifecycle.},
  number       = {5},
  journal      = {Software and Systems Modeling},
  author       = {Muctadir, Hossain Muhammad and Manrique Negrin, David A. and Gunasekaran, Raghavendran and Cleophas, Loek and van den Brand, Mark and Haverkort, Boudewijn R.},
  year         = {2024},
  month        = oct,
  pages        = {1275–1305},
  language     = {en}
}

 @article{Zhang_Wang_Cai_Wang_Guo_Zheng_2022,
  title        = {Digital twin and its applications: A survey},
  volume       = {123},
  issn         = {1433-3015},
  url          = {https://doi.org/10.1007/s00170-022-10445-3},
  doi          = {10.1007/s00170-022-10445-3},
  abstractnote = {Digital twin is a technology that integrates multi-physical, multi-scale, and multi-disciplinary attributes. At the same time, it has the characteristics of real-time synchronization, faithful mapping, and high fidelity. It can realize the interaction and integration of physical world and information world. In recent years, digital twin technology has attracted the attention of academic and business circles, especially its application. Based on this background, this paper summarizes the concept and evolution of digital twin, studies the application tools and platforms of digital twin, and discusses the relationship between digital twin and related technologies. Then we focus on the application scenarios of digital twin, and summarize the new trends and requirements of digital twin application. The purpose of this paper is to provide reference for the practice of digital twin concept and technology in related fields in the future.},
  number       = {11},
  journal      = {The International Journal of Advanced Manufacturing Technology},
  author       = {Zhang, Rui and Wang, Fang and Cai, Jun and Wang, Yan and Guo, Hongfei and Zheng, Jingsha},
  year         = {2022},
  month        = dec,
  pages        = {4123–4136},
  language     = {en}
}

 @article{Botín-Sanabria_2022,
  title        = {Digital Twin Technology Challenges and Applications: A Comprehensive Review},
  volume       = {14},
  rights       = {http://creativecommons.org/licenses/by/3.0/},
  issn         = {2072-4292},
  url          = {https://www.mdpi.com/2072-4292/14/6/1335},
  doi          = {10.3390/rs14061335},
  abstractnote = {A digital twin is a virtual representation of a physical object or process capable of collecting information from the real environment to represent, validate and simulate the physical twin’s present and future behavior. It is a key enabler of data-driven decision making, complex systems monitoring, product validation and simulation and object lifecycle management. As an emergent technology, its widespread implementation is increasing in several domains such as industrial, automotive, medicine, smart cities, etc. The objective of this systematic literature review is to present a comprehensive view on the DT technology and its implementation challenges and limits in the most relevant domains and applications in engineering and beyond.},
  number       = {6},
  journal      = {Remote Sensing},
  publisher    = {Multidisciplinary Digital Publishing Institute},
  author       = {Botín-Sanabria, Diego M. and Mihaita, Adriana-Simona and Peimbert-García, Rodrigo E. and Ramírez-Moreno, Mauricio A. and Ramírez-Mendoza, Ricardo A. and Lozoya-Santos, Jorge de J.},
  year         = {2022},
  month        = jan,
  pages        = {1335},
  language     = {en}
}

 @article{Kshetri_2021,
  title        = {The Economics of Digital Twins},
  volume       = {54},
  issn         = {1558-0814},
  url          = {https://ieeexplore.ieee.org/document/9399932},
  doi          = {10.1109/MC.2021.3055683},
  abstractnote = {Digital twins provide a number of economic, health, social, and environmental benefits. Their value can be amplified by combining them with other technologies and tools.},
  number       = {4},
  journal      = {Computer},
  author       = {Kshetri, Nir},
  year         = {2021},
  month        = apr,
  pages        = {86–90}
}

 @article{Gerlach_Zarnitz_2021,
  title        = {Digital Supply Chain Twins—Conceptual Clarification, Use Cases and Benefits},
  volume       = {5},
  rights       = {http://creativecommons.org/licenses/by/3.0/},
  issn         = {2305-6290},
  url          = {https://www.mdpi.com/2305-6290/5/4/86},
  doi          = {10.3390/logistics5040086},
  abstractnote = {Background: Digital supply chain twins (DSCT) are gaining increased attention in academia and practice as they emerge as one of the most important trends in logistics and supply chain management (LSCM). Still, there seems to be no common understanding of the term in scientific literature. Moreover, the broad field of LSCM allows for a multitude of feasible application areas and use cases, yet there exists no conclusive list of them as to date. Methods: This study builds upon a systematic literature review of 66 DSCT articles to identify application areas of DSCT in LSCM as well as specific use cases and their respective intended benefits. Results: To start with, the study derives a unified definition of DSCTs, including possible scopes of applications. Afterwards, five application areas of DSCT in LSCM are synthesized as well as 14 individual use cases and their respective intended benefits. Conclusions: The study leads towards a conceptual clarification of DSCT that is of importance for research and practice alike. For managers it additionally provides up-to-date use cases to guide DSCT applications in practice.},
  number       = {4},
  journal      = {Logistics},
  publisher    = {Multidisciplinary Digital Publishing Institute},
  author       = {Gerlach, Benno and Zarnitz, Simon and Nitsche, Benjamin and Straube, Frank},
  year         = {2021},
  month        = dec,
  pages        = {86},
  language     = {en}
}

 @article{Tripathi_2024,
  title        = {Stakeholders collaborations, challenges and emerging concepts in digital twin ecosystems},
  volume       = {169},
  issn         = {0950-5849},
  url          = {https://www.sciencedirect.com/science/article/pii/S0950584924000296},
  doi          = {10.1016/j.infsof.2024.107424},
  abstractnote = {Context:
                  Digital twin (DT) ecosystems are rapidly evolving, connecting many stakeholders, such as manufacturers, customers, and application platform providers. These ecosystems require collaboration and interaction between diverse actors to create value. This study delves into the collaboration of such stakeholders within DT-focused ecosystems.
                  Objective:
                  This research aims to understand stakeholder collaboration within DT ecosystems, identify potential challenges, and provide insights for managing these stakeholders. It also seeks to define the DT ecosystem and its implications for both research and practice.
                  Method:
                  A systematic literature review was conducted, supplemented by empirical evidence gathered from interviews with DT experts who were knowledgeable about the DT ecosystem. The study also analyzed DT systems, stakeholder roles, and the challenges with ecosystem-focused DT development.
                  Results:
                  The study identified various stakeholders and their roles in adding value to a DT ecosystem. It highlighted the benefits of stakeholder collaboration, such as knowledge gain during DT system development. The research also revealed the technical and non-technical challenges encountered in ecosystem-focused DTs, emphasizing the importance of standardization as a solution. A new definition of the DT ecosystem was proposed, emphasizing its data-driven nature, interconnected DTs, stakeholder value creation, and technology enablement.
                  Conclusion:
                  Stakeholder collaboration is pivotal in DT ecosystems, with each actor playing a distinct role. Addressing challenges, especially through standardization (OPC UA and ISO 23247), can lead to more efficient and coherent DT ecosystems. The insights provided by this study can guide industries in designing, developing, and maintaining their DT ecosystems, ensuring value creation and stakeholder satisfaction. Future research avenues that emphasize the importance of understanding the challenges involved and deploy appropriate solutions were suggested.},
  journal      = {Information and Software Technology},
  author       = {Tripathi, Nirnaya and Hietala, Heidi and Xu, Yueqiang and Liyanage, Reshani},
  year         = {2024},
  month        = may,
  pages        = {107424}
}

 @article{Nativi_2021,
  title        = {Digital Ecosystems for Developing Digital Twins of the Earth: The Destination Earth Case},
  volume       = {13},
  rights       = {http://creativecommons.org/licenses/by/3.0/},
  issn         = {2072-4292},
  url          = {https://www.mdpi.com/2072-4292/13/11/2119},
  doi          = {10.3390/rs13112119},
  abstractnote = {This manuscript discusses the key characteristics of the Digital Ecosystems (DEs) model, which, we argue, is particularly appropriate for connecting and orchestrating the many heterogeneous and autonomous online systems, infrastructures, and platforms that constitute the bedrock of a digitally transformed society. Big Data and AI systems have enabled the implementation of the Digital Twin paradigm (introduced first in the manufacturing sector) in all the sectors of society. DEs promise to be a flexible and operative framework that allow the development of local, national, and international Digital Twins. In particular, the “Digital Twins of the Earth” may generate the actionable intelligence that is necessary to address global change challenges, facilitate the European Green transition, and contribute to realizing the UN Sustainable Development Goals (SDG) agenda. The case of the Destination Earth initiative and system is discussed in the manuscript as an example to address the broader DE concepts. In respect to the more traditional data and information infrastructural philosophy, DE solutions present important advantages as to flexibility and viability. However, designing and implementing an effective collaborative DE is far more difficult than a traditional digital system. DEs require the definition and the governance of a metasystemic level, which is not necessary for a traditional information system. The manuscript discusses the principles, patterns, and architectural viewpoints characterizing a thriving DE supporting the generation and operation of “Digital Twins of the Earth”. The conclusions present a set of conditions, best practices, and base capabilities for building a knowledge framework, which makes use of the Digital Twin paradigm and the DE approach to support decision makers with the SDG agenda implementation.},
  number       = {11},
  journal      = {Remote Sensing},
  publisher    = {Multidisciplinary Digital Publishing Institute},
  author       = {Nativi, Stefano and Mazzetti, Paolo and Craglia, Max},
  year         = {2021},
  month        = jan,
  pages        = {2119},
  language     = {en}
}

 @article{Klar_2024,
  title        = {Digital Twins’ Maturity: The Need for Interoperability},
  volume       = {18},
  issn         = {1937-9234},
  url          = {https://ieeexplore.ieee.org/abstract/document/10367836},
  doi          = {10.1109/JSYST.2023.3340422},
  abstractnote = {Digital twins have gained tremendous momentum since their conceptualization over 20 years ago, as more and more domains discover their value in driving efficiencies and reducing costs, while enabling technologies continue to advance. Originally aimed at product optimization and intelligent manufacturing, the range of applications for digital twins now spans entire complex, often highly interconnected systems such as ports, cities, and supply chains. Despite the increasing demand for sophisticated digital twinning solutions across all domains and scopes, their development is often still constrained by differing definitions, different understandings of their functional scope and design, and a lack of concrete methodology toward implementing a comprehensive digital twinning solution. Although there are already papers that evaluate the capabilities of existing digital twinning solutions on the basis of maturity levels, these usually consider the object to be twinned in isolation and are often domain-specific. With this article we address exactly this gap discussing how interoperability of digital twins can break physical boundaries of an isolated system, enabling system of systems joint optimization. We therefore consider interoperable digital twins to be the most mature twinning platforms, thus, we discuss in detail six digital twin maturity levels, departing from the interrelated contexts of ports, cities, and supply chains. Examples drawn from these domains demonstrate the need for interoperability toward optimizing processes and systems in realistic contexts, rather than in assumed isolation.},
  number       = {1},
  journal      = {IEEE Systems Journal},
  author       = {Klar, Robert and Arvidsson, Niklas and Angelakis, Vangelis},
  year         = {2024},
  month        = mar,
  pages        = {713–724}
}

 @book{Uslar_2012,
  title        = {The Common Information Model CIM: IEC 61968/61970 and 62325 - A practical introduction to the CIM},
  isbn         = {978-3-642-25215-0},
  abstractnote = {Within the Smart Grid, the combination of automation equipment, communication technology and IT is crucial. Interoperability of devices and systems can be seen as the key enabler of smart grids. Therefore, international initiatives have been started in order to identify interoperability core standards for Smart Grids.  IEC 62357, the so called Seamless Integration Architecture, is one of these very core standards, which has been identified by recent Smart Grid initiatives and roadmaps to be essential for building and managing intelligent power systems. The Seamless Integration Architecture provides an overview of the interoperability and relations between further standards from IEC TC 57 like the IEC 61970/61968: Common Information Model - CIM. CIM has proven to be a mature standard for interoperability and engineering; consequently, it is a cornerstone of the IEC Smart Grid Standardization Roadmap. This book provides an overview on how the CIM developed,in which international projects and roadmaps is has already been covered and describes the basic use cases for CIM. This book has been written for both Power Engineers trying to get to know the EMS and business IT part of Smart Grid and for Computer Scientist finding out where ICT technology is applied in EMS and DMS Systems. The book is divided into two parts dealing with the theoretical foundations and a practical part describing tools and use cases for CIM.},
  publisher    = {Springer Science \& Business Media},
  author       = {Uslar, Mathias and Specht, Michael and Rohjans, Sebastian and Trefke, Jörn and González, José M.},
  year         = {2012},
  month        = feb,
  language     = {en}
}

 @misc{opendigitaltwins_2025,
  title        = {Open Digital Twins Definition Language},
  rights       = {CC-BY-4.0},
  url          = {https://github.com/Azure/opendigitaltwins-dtdl},
  abstractnote = {Digital Twins Definition Language},
  publisher    = {Microsoft Azure},
  author       = {{Microsoft}},
  year         = {2025},
  month        = oct
}

 @article{Hou_2025,
  title        = {Model Context Protocol (MCP): Landscape, Security Threats, and Future Research Directions},
  url          = {http://arxiv.org/abs/2503.23278},
  doi          = {10.48550/arXiv.2503.23278},
  abstractnote = {The Model Context Protocol (MCP) is a standardized interface designed to enable seamless interaction between AI models and external tools and resources, breaking down data silos and facilitating interoperability across diverse systems. This paper provides a comprehensive overview of MCP, focusing on its core components, workflow, and the lifecycle of MCP servers, which consists of three key phases: creation, operation, and update. We analyze the security and privacy risks associated with each phase and propose strategies to mitigate potential threats. The paper also examines the current MCP landscape, including its adoption by industry leaders and various use cases, as well as the tools and platforms supporting its integration. We explore future directions for MCP, highlighting the challenges and opportunities that will influence its adoption and evolution within the broader AI ecosystem. Finally, we offer recommendations for MCP stakeholders to ensure its secure and sustainable development as the AI landscape continues to evolve.},
  note         = {arXiv:2503.23278 [cs]},
  number       = {arXiv:2503.23278},
  publisher    = {arXiv},
  author       = {Hou, Xinyi and Zhao, Yanjie and Wang, Shenao and Wang, Haoyu},
  year         = {2025},
  month        = apr
}

 @inbook{Grieves_2017,
  address      = {Cham},
  title        = {Digital Twin: Mitigating Unpredictable, Undesirable Emergent Behavior in Complex Systems},
  isbn         = {978-3-319-38756-7},
  url          = {https://doi.org/10.1007/978-3-319-38756-7_4},
  doi          = {10.1007/978-3-319-38756-7_4},
  abstractnote = {Systems do not simply pop into existence. They progress through lifecycle phases of creation, production, operations, and disposal. The issues leading to undesirable and unpredicted emergent behavior are set in place during the phases of creation and production and realized during the operational phase, with many of those problematic issues due to human interaction. We propose that the idea of the Digital Twin, which links the physical system with its virtual equivalent can mitigate these problematic issues. We describe the Digital Twin concept and its development, show how it applies across the product lifecycle in defining and understanding system behavior, and define tests to evaluate how we are progressing. We discuss how the Digital Twin relates to Systems Engineering and how it can address the human interactions that lead to “normal accidents.” We address both Digital Twin obstacles and opportunities, such as system replication and front running. We finish with NASA’s current work with the Digital Twin.},
  booktitle    = {Transdisciplinary Perspectives on Complex Systems: New Findings and Approaches},
  publisher    = {Springer International Publishing},
  author       = {Grieves, Michael and Vickers, John},
  editor       = {Kahlen, Franz-Josef and Flumerfelt, Shannon and Alves, Anabela},
  year         = {2017},
  pages        = {85–113},
  language     = {en}
}

 @article{Jiang_2021,
  title        = {Industrial applications of digital twins},
  volume       = {379},
  url          = {https://royalsocietypublishing.org/doi/full/10.1098/rsta.2020.0360},
  doi          = {10.1098/rsta.2020.0360},
  abstractnote = {A digital twin (DT) is classically defined as the virtual replica of a real-world product, system, being, communities, even cities that are continuously updated with data from its physical counterpart, as well as its environment. It bridges the virtual cyberspace with the physical entities and, as such, is considered to be the pillar of Industry 4.0 and the innovation backbone of the future. A DT is created and used throughout the whole life cycle of the entity it replicates, from cradle to grave, so to speak. This article focuses on the present state of the art of DTs, concentrating on the use of DTs in industry in the context of smart manufacturing, especially from the point of view of plantwide optimization. The main capabilities of DTs (mirroring, shadowing and threading) are discussed in this context. The article concludes with a perspective on the future.
                  
                  This article is part of the theme issue ‘Towards symbiotic autonomous systems’.},
  number       = {2207},
  journal      = {Philosophical Transactions of the Royal Society A: Mathematical, Physical and Engineering Sciences},
  publisher    = {Royal Society},
  author       = {Jiang, Yuchen and Yin, Shen and Li, Kuan and Luo, Hao and Kaynak, Okyay},
  year         = {2021},
  month        = aug,
  pages        = {20200360}
}

 @report{Budiardjo_2021,
  title       = {Digital twin system interoperability framework},
  institution = {Tech. rep. Digital Twin Consortium, East Lansing, Michigan},
  author      = {Budiardjo, Anto and Migliori, Doug},
  year        = {2021}
}

 @article{Dietz_2020,
  title    = {Digital Twin: Empowering Enterprises Towards a System-of-Systems Approach},
  volume   = {62},
  issn     = {1867-0202},
  url      = {https://doi.org/10.1007/s12599-019-00624-0},
  doi      = {10.1007/s12599-019-00624-0},
  number   = {2},
  journal  = {Business \& Information Systems Engineering},
  author   = {Dietz, Marietheres and Pernul, Günther},
  year     = {2020},
  month    = apr,
  pages    = {179–184},
  language = {en}
}

 @book{Russell_2020,
  address      = {Hoboken, NJ},
  title        = {Artificial Intelligence: A Modern Approach},
  isbn         = {978-0-13-461099-3},
  abstractnote = {The most comprehensive, up-to-date introduction to the theory and practice of artificial intelligence The long-anticipated revision of Artificial Intelligence: A Modern Approach explores the full breadth and depth of the field of artificial intelligence (AI). The 4th Edition brings readers up to date on the latest technologies, presents concepts in a more unified manner, and offers new or expanded coverage of machine learning, deep learning, transfer learning, multiagent systems, robotics, natural language processing, causality, probabilistic programming, privacy, fairness, and safe AI.},
  publisher    = {Pearson},
  author       = {Russell, Stuart and Norvig, Peter},
  year         = {2020},
  language     = {en}
}

 @misc{Anthropic_2024,
  title    = {What is the Model Context Protocol (MCP)?},
  url      = {https://modelcontextprotocol.io/docs/getting-started/intro},
  journal  = {Model Context Protocol},
  language = {en},
  author   = {{Anthropic}},
  year     = {2025},
  month    = oct
}

 @online{Google_A2A_2025,
  title    = {What is A2A? - A2A Protocol},
  url      = {https://a2a-protocol.org/latest/topics/what-is-a2a/},
  journal  = {Agent2Agent (A2A) Protocol},
  author   = {Google},
  language = {en},
  year     = {2025},
  month    = oct
}

@online{LangChainOverview,
  title = {{{LangChain}} Overview},
  url = {https://docs.langchain.com/oss/python/langchain/overview},
  urldate = {2025-10-21},
  langid = {english},
  organization = {LangChain},
  year     = {2025}
}

@online{googleAgentDevelopmentKit,
  title = {Agent {{Development Kit}}},
  author = {{Google}},
  url = {https://google.github.io/adk-docs},
  urldate = {2025-10-22},
  abstract = {Build powerful multi-agent systems with Agent Development Kit},
  langid = {english},
  year = {2025}
}

@online{eclipseEclipseDittoOpen2025,
  title = {Eclipse {{Ditto}}™ • Open Source Framework for Digital Twins in the {{IoT}}},
  author = {{Eclipse}},
  year = {2025},
  url = {https://eclipse.dev/ditto/index.html},
  urldate = {2025-10-22},
  langid = {english}
}

@techreport{kitchenham2007,
  type = {{{EBSE Technical Report}}},
  title = {Guidelines for Performing Systematic Literature Reviews in Software Engineering},
  author = {Kitchenham, Barbara and Charters, Stuart},
  year = 2007,
  month = jul,
  number = {EBSE-2007-01},
  institution = {{Keele University and Durham University}}
}

@article{xiaGenerationAssetAdministration2024,
  title = {Generation of {{Asset Administration Shell With Large Language Model Agents}}: {{Toward Semantic Interoperability}} in {{Digital Twins}} in the {{Context}} of {{Industry}} 4.0},
  shorttitle = {Generation of {{Asset Administration Shell With Large Language Model Agents}}},
  author = {Xia, Yuchen and Xiao, Zhewen and Jazdi, Nasser and Weyrich, Michael},
  year = 2024,
  journal = {IEEE Access},
  volume = {12},
  pages = {84863--84877},
  issn = {2169-3536},
  doi = {10.1109/ACCESS.2024.3415470},
  urldate = {2025-10-24},
  abstract = {This research introduces a novel approach for achieving semantic interoperability in digital twins and assisting the creation of Asset Administration Shell (AAS) as digital twin model within the context of Industry 4.0. The foundational idea of our research is that the communication based on semantics and the generation of meaningful textual data are directly linked, and we posit that these processes are equivalent if the exchanged information can be serialized in text form. Based on this, we construct a ``semantic node'' data structure in our research to capture the semantic essence of textual data. Then, a system powered by large language models is designed and implemented to process the ``semantic node'' and generate standardized digital twin models (AAS instance models in the context of Industry 4.0) from raw textual data collected from datasheets describing technical assets. Our evaluation demonstrates an effective generation rate of 62-79\%, indicating a substantial proportion of the information from the source text can be translated error-free to the target digital twin instance model with the generative capability of large language models. This result has a direct application in the context of Industry 4.0, and the designed system is implemented as a data model generation tool for reducing the manual effort in creating AAS model by automatically translating unstructured textual data into a standardized AAS model. The generated AAS model can be integrated into AAS-compliant digital twin software for seamless information exchange and communication. In our evaluation, a comparative analysis of different LLMs and an in-depth ablation study of Retrieval-Augmented Generation (RAG) mechanisms provide insights into the effectiveness of LLM systems for interpreting technical concepts and translating data. Our findings emphasize LLMs' capability to automate AAS instance creation and contribute to the broader field of semantic interoperability for digital twins in industrial applications. The prototype implementation and evaluation results are presented on our GitHub Repository: https://github.com/YuchenXia/AASbyLLM.},
  keywords = {Asset administration shell,Augmented reality,Context modeling,Data models,digital twin,Digital twins,Fourth Industrial Revolution,generative AI,industry 4.0,Information retrieval,Interoperability,large language model,Large language models,retrieval-augmented generation,semantic interoperability,Semantics,Unified modeling language}
}

@article{afzalDelvingDigitalTwin2023,
  title = {Delving into the {{Digital Twin Developments}} and {{Applications}} in the {{Construction Industry}}: {{A PRISMA Approach}}},
  shorttitle = {Delving into the {{Digital Twin Developments}} and {{Applications}} in the {{Construction Industry}}},
  author = {Afzal, Muhammad and Li, Rita Yi Man and Shoaib, Muhammad and Ayyub, Muhammad Faisal and Tagliabue, Lavinia Chiara and Bilal, Muhammad and Ghafoor, Habiba and Manta, Otilia},
  year = 2023,
  month = jan,
  journal = {Sustainability},
  volume = {15},
  number = {23},
  pages = {16436},
  publisher = {Multidisciplinary Digital Publishing Institute},
  issn = {2071-1050},
  doi = {10.3390/su152316436},
  urldate = {2025-10-25},
  abstract = {Construction 4.0 is witnessing exponential growth in digital twin (DT) technology developments and applications, revolutionizing the adoption of building information modelling (BIM) and other emerging technologies used throughout the built environment lifecycle. BIM provides technologies, procedures, and data schemas representing building components and systems. At the same time, the DT enhances this with real-time data for integrating cyber-physical systems, enabling live asset monitoring and better decision making. Despite being in the early stages of development, DT applications have rapidly progressed in the AEC sector, resulting in a diverse literature landscape due to the various technologies and parameters involved in fully developing the DT technology. The intricate complexities inherent in digital twin advancements have confused professionals and researchers. This confusion arises from the nuanced distinctions between the two technologies, i.e., BIM and DT, causing a convergence that hinders realizing their potential. To address this confusion and lead to a swift development of DT technology, this study provides a holistic review of the existing research focusing on the critical components responsible for developing the applications of DT technology in the construction industry. It highlights five crucial elements: technologies, maturity levels, data layers, enablers, and functionalities. Additionally, it identifies research gaps and proposes future avenues for streamlined DT developments and applications in the AEC sector. Future researchers and practitioners can target data integrity, integration and transmission, bi-directional interoperability, non-technical factors, and data security to achieve mature digital twin applications for AEC practices. This study highlights the growing significance of DTs in construction and provides a foundation for further advancements in this field to harness its potential to transform built environment practices. It also pinpoints the latest developments in AI, namely the large language model (LLM) and retrieval-augmented generation (RAG)'s implications for DT education, policies, and the construction industry's practices.},
  copyright = {http://creativecommons.org/licenses/by/3.0/},
  langid = {english},
  keywords = {bi-directional interoperability,building information modelling,construction 4.0,digital transformation,digital twin,generative AI,PRISMA,sustainability}
}

@article{banadArtificialIntelligenceMachine2025,
  title = {Artificial Intelligence and Machine Learning for Smart Grids: From Foundational Paradigms to Emerging Technologies with Digital Twin and Large Language Model-Driven Intelligence},
  shorttitle = {Artificial Intelligence and Machine Learning for Smart Grids},
  author = {Banad, Yaser M. and Sharif, Sarah S. and Rezaei, Zahra},
  year = 2025,
  month = oct,
  journal = {Energy Conversion and Management: X},
  volume = {28},
  pages = {101329},
  issn = {2590-1745},
  doi = {10.1016/j.ecmx.2025.101329},
  urldate = {2025-10-25},
  abstract = {The evolution of modern power systems into smart grids is increasingly powered by Artificial Intelligence (AI) and Machine Learning (ML), which provide effective solutions for managing renewable intermittency, dynamic demand, and cybersecurity challenges. This paper presents a comprehensive review of AI/ML applications in smart grids, tracing their development from foundational paradigms to cutting-edge technologies such as Federated Learning (FL), Generative AI (GenAI), Large Language Models (LLMs), the Artificial Intelligence of Things (AIoT), and Digital Twin (DT)-driven intelligence. Enabling infrastructures, including IoT, 5G, edge--cloud ecosystems, and ML-based smart sensors, are discussed alongside advanced approaches such as multi-agent systems. Key applications explored include load forecasting, predictive maintenance, anomaly and cyber-attack detection, demand-side management, and electric vehicle integration. Special emphasis is placed on Digital Twin and LLM architectures, which enable real-time cyber-physical replicas and context-aware reasoning, thus improving predictive analytics, resilience, and autonomous decision-making. Despite notable advancements, challenges remain in interoperability, data privacy, computational scalability, adversarial robustness, and ethical constraints. By synthesizing these insights, the study highlights the transformative role of AI in creating resilient, sustainable, and intelligent energy systems, and outlines future research trajectories toward standardized DT frameworks, active learning paradigms, and LLM-driven energy intelligence.},
  keywords = {Artificial intelligence,Digital twin,Energy management,Generative AI,Large language models,Machine learning,Renewable energy,Smart grids}
}

@article{fuAIaugmentedElectrochemicalModel2025,
  title = {{{AI-augmented}} Electrochemical Model for Lithium-Ion Battery: {{Recent}} Advances and Perspectives},
  shorttitle = {{{AI-augmented}} Electrochemical Model for Lithium-Ion Battery},
  author = {Fu, Juncheng and Song, Zhengxiang and Meng, Jinhao and Guo, Jia and Yang, Kun and Liu, Wenchao and Huan, Le},
  year = 2025,
  month = oct,
  journal = {Journal of Energy Chemistry},
  issn = {2095-4956},
  doi = {10.1016/j.jechem.2025.10.008},
  urldate = {2025-10-25},
  abstract = {With the rapid development of electric vehicles and grid-scale renewable integration, the demand for lithium-ion batteries (LIBs) has significantly increased with high expectations on enhanced energy density, cycle stability, and failure resilience. Electrochemical models (EMs), serving as pivotal mechanism-driven analytical frameworks in battery research and applications, demonstrate unprecedented quantitative fidelity in characterizing intricate multi-physics dynamics for the next-generation battery management systems (BMS). The breakthrough innovations in artificial intelligence (AI) driven methods have revolutionized the dynamic modeling of LIBs. However, the deployment of AI-augmented EMs in BMS faces significant identifiability challenges due to strong parameter coupling. In addition, research on model simplification, parameter determination, and dynamic parameter identification remains largely fragmented. There is a lack of a comprehensive review to pave the way for the cross-domain innovations in BMS. To fill this gap, this paper presents a systematic review of the EMs for LIBs and examines the advancements in parameter determination techniques from both experimental measurement and numerical simulation perspectives. Besides, a comprehensive assessment of the progress in parameter identification from the standpoint of dynamic recognition is presented, encompassing both model-based approaches and intelligent methods. Additionally, from the BMS standpoint, the strengths and limitations of existing approaches are evaluated. Finally, a coordinated framework for multi-stage identification needs to be established in the future. The potential of digital twins (DT), deep reinforcement learning (DRL), and large language models (LLMs) in enhancing EMs also warrants further exploration. The purpose of this work is to provide insights and guidance for the future development of EMs in LIB applications.},
  keywords = {Dynamic electrochemical model,Intelligent approach,Lithium-ion battery,Parameterization}
}

@article{hurtadoSelfconfigurableManufacturingIndustrial2025,
  title = {Self-Configurable {{Manufacturing Industrial Agents}} ({{SMIA}}): A Standardized Approach for Digitizing Manufacturing Assets},
  shorttitle = {Self-Configurable {{Manufacturing Industrial Agents}} ({{SMIA}})},
  author = {Hurtado, Ekaitz and Burgos, Arantzazu and Armentia, Aintzane and Casquero, Oskar},
  year = 2025,
  month = sep,
  journal = {Journal of Industrial Information Integration},
  volume = {47},
  pages = {100915},
  issn = {2452-414X},
  doi = {10.1016/j.jii.2025.100915},
  urldate = {2025-10-25},
  abstract = {The integration of heterogeneous industrial assets into flexible and distributed manufacturing environments remains a fundamental challenge in the evolution of Industry 4.0. Although standardization efforts -- such as the Asset Administration Shell (AAS) and the Capability-Skill-Service (CSS) model promoted by the Plattform Industrie initiative, the OWL ontology language promoted by W3C, and the FIPA Agent Communication Language promoted by IEEE -- offer structured frameworks for interoperability, their combined application still presents unresolved implementation challenges. This paper introduces SMIA (Self-configurable Manufacturing Industrial Agents), a dual-layer solution that operationalizes these standards by converging semantic modeling and distributed software execution. First, SMIA proposes a methodology for characterizing proactive AAS by enriching their descriptions with an OWL ontology based on the CSS model. Second, it provides a software toolchain that automatically generates Digital Twins --implemented as FIPA-compliant industrial agents using SPADE -- from these enriched AAS descriptions. The resulting agents can react to external events, coordinating with peers and executing domain-specific skills within a standardized I4.0 communication framework. Built following an Open Source Software Engineering approach, SMIA leverages mature tools such as Eclipse BaSyx, OWLReady2 and SPADE, showcasing a replicable and extensible approach to the adoption of industrial standards in practice. A preliminary validation in a robotic logistics scenario demonstrates its feasibility and adaptability.},
  keywords = {Asset administration shell (AAS),Capability-skill-service (CSS) model,Digital Twin,Flexible manufacturing,Multi-agent systems,Standardization}
}

@article{juarezSemanticModularOrchestration2025,
  title = {Semantic and Modular Orchestration of {{AI-driven}} Digital Twins for Industrial Interoperability and Optimization},
  author = {Juarez, Maria Gabriela Juarez and Giret, Adriana and Botti, Vicente},
  year = 2025,
  month = nov,
  journal = {Journal of Industrial Information Integration},
  volume = {48},
  pages = {100959},
  issn = {2452-414X},
  doi = {10.1016/j.jii.2025.100959},
  urldate = {2025-10-25},
  abstract = {Digital Twins (DTs) are foundational in smart manufacturing, supporting data-driven monitoring and optimization. Yet, many implementations remain monolithic, limiting interoperability and reusability. This paper introduces a semantic and modular architecture for orchestrating AI-driven DTs, designed to enable scalable integration and standardized coordination across industrial systems. The system employs a semantic API aligned with NGSI-LD, to expose industrial entities such as processes, anomalies, assets, and contextual KPIs (e.g., energy usage, CO2 emissions, tool wear, product quality). AI techniques ranging from threshold adjustment to symbolic learning are encapsulated as modular agents, each performing targeted optimization tasks. These agents operate over the semantic API, which ensures consistent, interpretable interactions across modules. A Manager and a Recommender agent are defined to coordinate execution; while not yet deployed at runtime, their logic is implemented through semantic interfaces that support traceable, modular activation. The system is validated using synthetic data simulating machining, assembly, and inspection tasks. Results show measurable improvements in sustainability-related KPIs following each module's activation. More importantly, the semantic orchestration layer enables modularity, interoperability, and AI reuse. This work contributes a standards-compliant foundation for next-generation DTs, supporting integration with ecosystems such as FIWARE, Catena-X, and IDS, and aligned with the principles of Industry 4.0 and 5.0.},
  keywords = {Industrial interoperability,Industry 4.0/5.0,Modular architecture,Multi-agent systems,NGSI-LD,Semantic digital twins}
}

@article{karapanagiotisEnablingInteroperableHuman2025,
  title = {Enabling Interoperable Human--{{AI}} Teaming for Automation in Construction and Manufacturing via {{Digital Twins}} and {{Sliding Work Sharing}} Ontologies},
  author = {Karapanagiotis, Pantelis and Kottagaha W.M., Kolitha and Rovere, Diego and Bokhorst, Jos A. C. and Valdata, Andrea and Emmanouilidis, Christos},
  year = 2025,
  month = nov,
  journal = {Journal of Industrial Information Integration},
  volume = {48},
  pages = {100962},
  issn = {2452-414X},
  doi = {10.1016/j.jii.2025.100962},
  urldate = {2025-10-25},
  abstract = {This paper introduces an ontology system to support dynamic, explainable, and human-centric collaboration between humans and artificial intelligence-enabled non-human agents in cyber--physical environments. In this setting, Digital Twins (digital models of physical systems or processes that mirror their real-time state) and Human Digital Twins (digital representations of individual humans, including their physiological or cognitive states) may provide information to enable an appropriate dynamic allocation of the work that can be shared by humans and AI actors (i.e., sliding work sharing). A novel upper-level Sliding Work Sharing ontology is defined to support semantic interoperability and reasoning across diverse domains, facilitating sliding work sharing in complex environments. The ontology is grounded in Industry 5.0 concepts and built upon the Industrial Ontology Foundry core ontology. It extends conventional scheduling ontologies by incorporating key constructs for Digital Twins, Human Digital Twins, and dynamic task flows. We validate the ontology through two use cases from the domains of automation in construction and manufacturing. The collaborative construction case involves robots and humans, while the manufacturing one integrates legacy systems, artificial intelligence actors, and human planners. The developed ontology system is evaluated for its coverage and expressiveness through a novel Retrieval-Augmented Generation based methodology, applied on diverse Large Language Models to derive competency questions from external sources. This approach enhances conventional ontology validation techniques with a scalable and unbiased alternative. Logical consistency is confirmed using a range of standard reasoners. Our results demonstrate that the Sliding Work Sharing ontology has considerable flexibility and potential to advance human--AI teaming in future work environments.},
  keywords = {Construction,Human-AI teaming,Human-centric collaboration,Manufacturing,Ontology,Robotics,Sliding Work Sharing}
}

@article{shaikhMachineIntelligenceMedical2023,
  title = {Machine Intelligence and Medical Cyber-Physical System Architectures for Smart Healthcare: {{Taxonomy}}, Challenges, Opportunities, and Possible Solutions},
  shorttitle = {Machine Intelligence and Medical Cyber-Physical System Architectures for Smart Healthcare},
  author = {Shaikh, Tawseef Ayoub and Rasool, Tabasum and Verma, Prabal},
  year = 2023,
  month = dec,
  journal = {Artificial Intelligence in Medicine},
  volume = {146},
  pages = {102692},
  issn = {0933-3657},
  doi = {10.1016/j.artmed.2023.102692},
  urldate = {2025-10-25},
  abstract = {Hospitals use medical cyber-physical systems (MCPS) more often to give patients quality continuous care. MCPS isa life-critical, context-aware, networked system of medical equipment. It has been challenging to achieve high assurance in system software, interoperability, context-aware intelligence, autonomy, security and privacy, and device certifiability due to the necessity to create complicated MCPS that are safe and efficient. The MCPS system is shown in the paper as a newly developed application case study of artificial intelligence in healthcare. Applications for various CPS-based healthcare systems are discussed, such as telehealthcare systems for managing chronic diseases (cardiovascular diseases, epilepsy, hearing loss, and respiratory diseases), supporting medication intake management, and tele-homecare systems. The goal of this study is to provide a thorough overview of the essential components of the MCPS from several angles, including design, methodology, and important enabling technologies, including sensor networks, the Internet of Things (IoT), cloud computing, and multi-agent systems. Additionally, some significant applications are investigated, such as smart cities, which are regarded as one of the key applications that will offer new services for industrial systems, transportation networks, energy distribution, monitoring of environmental changes, business and commerce applications, emergency response, and other social and recreational activities.The four levels of an MCPS's general architecture---data collecting, data aggregation, cloud processing, and action---are shown in this study. Different encryption techniques must be employed to ensure data privacy inside each layer due to the variations in hardware and communication capabilities of each layer. We compare established and new encryption techniques based on how well they support safe data exchange, secure computing, and secure storage. Our thorough experimental study of each method reveals that, although enabling innovative new features like secure sharing and safe computing, developing encryption approaches significantly increases computational and storage overhead. To increase the usability of newly developed encryption schemes in an MCPS and to provide a comprehensive list of tools and databases to assist other researchers, we provide a list of opportunities and challenges for incorporating machine intelligence-based MCPS in healthcare applications in our paper's conclusion.},
  keywords = {Big data,CPS Architectures,Dew computing,Digital twin,Internet of things,Medical cyber-physical systems,Security and privacy}
}

@article{shiCognitiveDigitalTwins2026,
  title = {Cognitive Digital Twins for Capability Matching toward Reconfigurable Manufacturing: {{Leveraging}} Asset Administration Shells and Large Language Models},
  shorttitle = {Cognitive Digital Twins for Capability Matching toward Reconfigurable Manufacturing},
  author = {Shi, Dachuan and Meyer, Olga and Fan, Zhi and Wang, Hao and Bauernhansl, Thomas},
  year = 2026,
  month = feb,
  journal = {Robotics and Computer-Integrated Manufacturing},
  volume = {97},
  pages = {103105},
  issn = {0736-5845},
  doi = {10.1016/j.rcim.2025.103105},
  urldate = {2025-10-25},
  abstract = {Reconfigurable manufacturing (RM) has emerged to support mass customization, which leads to frequent changes in production processes. RM necessitates the rapid reallocation of production resources to accommodate these evolving demands. To address this challenge, we propose a cognitive digital twin (CDT) system that integrates Asset Administration Shells (AAS) and large language models (LLMs) for adaptively matching between production processes and resource capabilities. Our approach centers on the structured representation of knowledge related to products, processes, and resources (PPR) using the AAS and leveraging this foundation for capability matching through the LLM. First, a methodology for developing interoperable AAS submodels (SM) is represented. Based on this, the SM templates of PPR are developed, serving as the knowledge base of the CDT. Next, we propose a capability matching mechanism using the LLM with chain-of-thought prompting. Finally, we design and implement an IT architecture that integrates an LLM-based retrieval-augmented generation system for executing capability matching alongside an AAS server for hosting AAS instances with dynamic values. The proposed CDT system enables the dynamic allocation of production resources to process steps, and is demonstrated and evaluated in a machining center use case. It effectively supports planning customized machining tasks through AAS-based knowledge representation and LLM-powered capability matching.},
  keywords = {Asset administration shell,Capability matching,Cognitive digital twin,Large language model,Reconfigurable manufacturing,Retrieval-augmented generation}
}

@article{shiDualDataMapping2025,
  title = {Dual Data Mapping with Fine-Tuned Large Language Models and Asset Administration Shells toward Interoperable Knowledge Representation},
  author = {Shi, Dachuan and Meyer, Olga and Oberle, Michael and Bauernhansl, Thomas},
  year = 2025,
  month = feb,
  journal = {Robotics and Computer-Integrated Manufacturing},
  volume = {91},
  pages = {102837},
  issn = {0736-5845},
  doi = {10.1016/j.rcim.2024.102837},
  urldate = {2025-10-25},
  abstract = {In the context of Industry 4.0, ensuring the compatibility of digital twins (DTs) with existing software systems in the manufacturing sector presents a significant challenge. The Asset Administration Shell (AAS), conceptualized as the standardized DT for an asset, offers a powerful framework that connects the DT with the established software infrastructure through interoperable knowledge representation. Although the IEC 63278 series specifies the AAS metamodel, it lacks a matching strategy for automating the mapping between proprietary data from existing software and AAS information models. Addressing this gap, we introduce a novel dual data mapping system (DDMS) that utilizes a fine-tuned open-source large language model (LLM) for entity matching. This system facilitates not only the mapping between existing software and AAS models but also between AAS models and standardized vocabulary dictionaries, thereby enhancing the model's semantic interoperability. A case study within the injection molding domain illustrates the practical application of DDMS for the automated creation of AAS instances, seamlessly integrating the manufacturer's existing data. Furthermore, we extensively investigate the potential of fine-tuning decode-only LLMs as generative classifiers and encoding-based classifiers for the entity matching task. To this end, we establish two AAS-specific datasets by collecting and compiling AAS-related resources. In addition, supplementary experiments are performed on general entity-matching benchmark datasets to ensure that our empirical conclusions and insights are generally applicable. The experiment results indicate that the fine-tuned generative LLM classifier achieves slightly better results, while the encoding-based classifier enables much faster inference. Furthermore, the fine-tuned LLM surpasses all state-of-the-art approaches for entity matching, including GPT-4 enhanced with in-context learning and chain of thoughts. This evidence highlights the effectiveness of the proposed DDMS in bridging the interoperability gap within DT applications, offering a scalable solution for the manufacturing industry.},
  keywords = {Asset administration shell,Digital twin,Entity matching,Interoperability,Knowledge representation,Large language model}
}

@article{shiEnhancingRetrievalaugmentedGeneration2025,
  title = {Enhancing Retrieval-Augmented Generation for Interoperable Industrial Knowledge Representation and Inference toward Cognitive Digital Twins},
  author = {Shi, Dachuan and Li, Jianzhang and Meyer, Olga and Bauernhansl, Thomas},
  year = 2025,
  month = oct,
  journal = {Computers in Industry},
  volume = {171},
  pages = {104330},
  issn = {0166-3615},
  doi = {10.1016/j.compind.2025.104330},
  urldate = {2025-10-25},
  abstract = {The escalating volume and complexity of digital data within the manufacturing sector highlight an urgent need for an efficient knowledge representation and inference solution. Traditional approaches, which often rely on ontologies, knowledge graphs, or digital twins (DTs) for knowledge representation, and rule-based algorithms for inference, are becoming insufficient. The emergence of generative AI, particularly large language models (LLM) and retrieval-augmented generation (RAG), offers a more efficient and intelligent alternative. However, the performance of an RAG system is heavily dependent on the quality of retrieval results, which can be compromised by domain-specific knowledge and retrieval distractors. To address this challenge, we propose to enhance RAG systems tailored for the manufacturing industry in two aspects. First, we utilize the Asset Administration Shell (AAS), which represents the German industrial perspective on cognitive DTs, to create a representation of assets and knowledge in standardized information models. This establishes a robust foundation for the retrieval sources. Second, we propose a contrastive selection loss (CSL) to fine-tune an open-source LLM to refine the retrieval results. Fine-tuned LLMs possess higher efficiency and accuracy on task- and domain-specific datasets, while the CSL further enhances the model's ability to distinguish true positives from similar distractors. The enhanced RAG system is demonstrated in a robotic work cell integration use case and evaluated through a novel evaluation protocol. Additionally, the retrieval effectiveness of the RAG system, specifically the LLM fine-tuned with CSL, is extensively validated through statistical experiments. The results confirm its superior performance over state-of-the-art methods, including GPT-4 with in-context learning prompts and other fine-tuned models.},
  keywords = {Asset administration shell,Digital twin,Entity matching,Large language model,Retrieval-augmented generation}
}

@article{shiInteroperableInformationModelling2024,
  title = {Interoperable Information Modelling Leveraging Asset Administration Shell and Large Language Model for Quality Control toward Zero Defect Manufacturing},
  author = {Shi, Dachuan and Liedl, Philipp and Bauernhansl, Thomas},
  year = 2024,
  month = dec,
  journal = {Journal of Manufacturing Systems},
  volume = {77},
  pages = {678--696},
  issn = {0278-6125},
  doi = {10.1016/j.jmsy.2024.10.011},
  urldate = {2025-10-25},
  abstract = {In the era of Industry 4.0, Zero Defect Manufacturing (ZDM) has emerged as a prominent strategy for quality improvement, emphasizing data-driven approaches for defect prediction, prevention, and mitigation. The success of ZDM heavily depends on the availability and quality of data typically collected from diverse and heterogeneous sources during production and quality control, presenting challenges in data interoperability. Addressing this, we introduce a novel approach leveraging Asset Administration Shell (AAS) and Large Language Models (LLMs) for creating interoperable information models that incorporate semantic contextual information to enhance the interoperability of data integration in the quality control process. AAS, initiated by German industry stakeholders, shows a significant advancement in information modeling, blending ontology and digital twin concepts for the virtual representation of assets. In this work, we develop a systematic, use-case-driven methodology for AAS-based information modeling. This methodology guides the design and implementation of AAS models, ensuring model properties are presented in a unified structure and reference external standardized vocabularies to maintain consistency across different systems. To automate this referencing process, we propose a novel LLM-based algorithm to semantically search model properties within a standardized vocabulary repository. This algorithm significantly reduces manual intervention in model development. A case study in the injection molding domain demonstrates the practical application of our approach, showcasing the integration and linking of product quality and machine process data with the help of the developed AAS models. Statistical evaluation of our LLM-based semantic search algorithm confirms its efficacy in enhancing data interoperability. This methodology offers a scalable and adaptable solution for various industrial use cases, promoting widespread data interoperability in the context of Industry 4.0.},
  keywords = {Asset administration shell,Industry 4.0,Information modelling,Interoperability,Large language model,Ontology,Quality control,Zero defect manufacturing}
}

@article{soummaAIPoweredWearableSensors2025,
  title = {{{AI-Powered Wearable Sensors}} for {{Health Monitoring}} and {{Clinical Decision Making}}},
  author = {Soumma, Shovito Barua and Mamun, Abdullah and Ghasemzadeh, Hassan},
  year = 2025,
  month = oct,
  journal = {Current Opinion in Biomedical Engineering},
  pages = {100628},
  issn = {2468-4511},
  doi = {10.1016/j.cobme.2025.100628},
  urldate = {2025-10-25},
  abstract = {AI-powered wearable sensors are transforming remote health monitoring by enabling real-time diagnostics, personalized interventions and proactive disease management. This review synthesizes recent advances in AI-integrated biosensors across conditions such as diabetes, cardiovascular disease, neurodegenerative dis- orders, mental health, and maternal/neonatal care, while addressing challenges of scalability, privacy, interoperability, and model robustness. We highlight machine learning methods---including federated learning, transfer learning, and edge- AI---that enhance the processing of physiological signals i.e., glucose levels, gait patterns, and heart rate variability. Key innovations, including FDA-approved glucose monitors and digital twins for predictive health modeling, underscore the shift toward patient-centric and data-driven care. Yet, persistent gaps remain, including device heterogeneity, privacy concerns, and the need for adaptive models that generalize across populations. Emerging approaches such as large language models and counterfactual explanations provide contextualized insights and transparent decision-making. By bridging technical advances with clinical needs, this review charts a roadmap toward democratized, equitable, and precise healthcare.},
  keywords = {behavioral health,counterfactual,deep learning,digital twin,gait,glucose monitor,Human-in-the-loop,hydration,LLM,Mobile Health,Parkinson,personalized health monitoring,real-time monitor,stress,wearable sensor}
}

@article{wangDigitalTwinassistedService2024,
  title = {Digital Twin-Assisted Service Function Chaining in Multi-Domain Computing Power Networks with Multi-Agent Reinforcement Learning},
  author = {Wang, Kan and Yuan, Peng and Jan, Mian Ahmad and Khan, Fazlullah and Gadekallu, Thippa Reddy and Kumari, Saru and Pan, Hao and Liu, Lei},
  year = 2024,
  month = sep,
  journal = {Future Generation Computer Systems},
  volume = {158},
  pages = {294--307},
  issn = {0167-739X},
  doi = {10.1016/j.future.2024.04.025},
  urldate = {2025-10-25},
  abstract = {The emerging computing power network (CPN) is believed to undergo the paradigm reformation of network function virtualization (NFV) and service function chaining (SFC). It is prerequisite to explore the performance upper bound of NFV-assisted CPN before truly deploying the NFV and SFC technologies onto physical networks. Inspired by the application of digital twin (DT) in the industry and due to its advantage in synchronizing physical objects with their virtual replicas, we propose to use the DT to assist the SFC deployment in the multi-domain CPN, with the aid of multi-agent deep deterministic policy gradient (MADDPG) framework. First, we build a dynamic SFC mapping problem in the virtual twin network layer, by modeling the computing power, link bandwidth, delay performance and the VNF ordering as DT objects and constraints, to jointly optimize the energy consumption, end-to-end delay and the VNF re-deploying cost. Then, the prioritized experience replay and re-parameterization trick-empowered centralized training and decentralized execution MADDPG framework is utilized to learn the SFC deployment, by taking each domain controller as one agent. Finally, numerical experiments are carried out to validate the effectiveness of MADDPG in the cross-domain SFC deployment. For performance verification, the deployment success rate, number of crossed domains, energy consumption, end-to-end latency and load balancing degree are all taken as metrics, to show the performance of MADDPG compared to other learning frameworks.},
  keywords = {Digital twin,MADDPG,Multi-domain computing power network,Network function virtualization,Service function chain}
}

@article{xuMultiagentDigitalTwinning2025,
  title = {Multi-Agent Digital Twinning for Collaborative Logistics: {{Framework}} and Implementation},
  shorttitle = {Multi-Agent Digital Twinning for Collaborative Logistics},
  author = {Xu, Liming and Mak, Stephen and Schoepf, Stefan and Ostroumov, Michael and Brintrup, Alexandra},
  year = 2025,
  month = may,
  journal = {Journal of Industrial Information Integration},
  volume = {45},
  pages = {100799},
  issn = {2452-414X},
  doi = {10.1016/j.jii.2025.100799},
  urldate = {2025-10-25},
  abstract = {Collaborative logistics has been widely recognised as an effective avenue to reduce carbon emissions by enhanced truck utilisation and reduced travel distance. However, stakeholders' participation in collaborations is hindered by information-sharing barriers and absence of integrated systems. We, thus, in this paper addresses these barriers by investigating an integrated platform that facilitates collaboration through the integration of agents with digital twins. Specifically, we employ a multi-agent system approach to integrate stakeholders and physical assets in collaborative logistics, representing them as agents. We introduce a loosely-coupled system architecture that facilitates the connection between physical and digital systems, enabling the integration of agents with digital twins. Using this architecture, we implement a prototypical testbed. The resulting testbed, comprising a physical environment and a digital replica, is a digital twin that integrates distributed entities involved in collaborative logistics. Its effectiveness on integrating both physical and digital, stationary and mobile objects is demonstrated through a carrier collaboration scenario. This paper is among the few earliest efforts to examine the integration of agents and digital twin concepts in logistics sector and goes beyond the conceptual discussion of existing studies to the technical implementation of such integration.},
  keywords = {Carrier collaboration,Collaborative logistics,Digital twins,Integrated platform,Multi-agent system,Physical internet}
}

@article{tricco2018,
  title = {{{PRISMA Extension}} for {{Scoping Reviews}} ({{PRISMA-ScR}}): {{Checklist}} and {{Explanation}}},
  shorttitle = {{{PRISMA Extension}} for {{Scoping Reviews}} ({{PRISMA-ScR}})},
  author = {Tricco, Andrea C. and Lillie, Erin and Zarin, Wasifa and O'Brien, Kelly K. and Colquhoun, Heather and Levac, Danielle and Moher, David and Peters, Micah D.J. and Horsley, Tanya and Weeks, Laura and Hempel, Susanne and Akl, Elie A. and Chang, Christine and McGowan, Jessie and Stewart, Lesley and Hartling, Lisa and Aldcroft, Adrian and Wilson, Michael G. and Garritty, Chantelle and Lewin, Simon and Godfrey, Christina M. and Macdonald, Marilyn T. and Langlois, Etienne V. and {Soares-Weiser}, Karla and Moriarty, Jo and Clifford, Tammy and Tun{\c c}alp, {\"O}zge and Straus, Sharon E.},
  year = 2018,
  month = oct,
  journal = {Annals of Internal Medicine},
  volume = {169},
  number = {7},
  pages = {467--473},
  publisher = {American College of Physicians},
  issn = {0003-4819},
  doi = {10.7326/M18-0850},
  urldate = {2025-10-28},
  abstract = {Scoping reviews, a type of knowledge synthesis, follow a systematic approach to map evidence on a topic and identify main concepts, theories, sources, and knowledge gaps. Although more scoping reviews are being done, their methodological and reporting quality need improvement. This document presents the PRISMA-ScR (Preferred Reporting Items for Systematic reviews and Meta-Analyses extension for Scoping Reviews) checklist and explanation. The checklist was developed by a 24-member expert panel and 2 research leads following published guidance from the EQUATOR (Enhancing the QUAlity and Transparency Of health Research) Network. The final checklist contains 20 essential reporting items and 2 optional items. The authors provide a rationale and an example of good reporting for each item. The intent of the PRISMA-ScR is to help readers (including researchers, publishers, commissioners, policymakers, health care providers, guideline developers, and patients or consumers) develop a greater understanding of relevant terminology, core concepts, and key items to report for scoping reviews.}
}

